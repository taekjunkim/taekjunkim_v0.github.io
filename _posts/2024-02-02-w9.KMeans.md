---
title: "K-means clustering"
categories:
  - MachineLearning 
excerpt: "Unsupervised learning: clustering"
author_profile: false
sidebar:
    title: Machine Learning
    nav: sidebar_ML
usemathjax: true
---


## Beyond supervised learning

- Unsupervised learning
  - Clustering
  - Anomaly detection
- Recommender systems
- Reinforcement learning

## Applications of clustering

- Grouping similar news
- Market segmentation
- DNA analysis
- Astronomical data analysis

## K-means

- intuition
  1.  Assign each point to its closest centroid
  2.  Recompute the centroid
  3.  Repeat 1 and 2
- algorithm
  1.  Randomly initialize $$K$$ cluster centroid: $$\mu_{1}, \mu_{2}, ..., \mu_{K}$$
  2.  Repeat
      - Assign points to cluster centroids
        - $$c^{(i)}=min_{k}||x^{(i)}-\mu_{k}||^2$$
      - Move cluster centroid
        - $$\mu_{k}$$: average (mean) of points assigned to cluster $$k$$
- Optimization objective
  - $$c^{(i)}$$: index of cluster $$(1,2,3,...,K)$$ to which example $$x^{(i)}$$ is currently assigned
  - $$\mu_{k}$$: cluster centroid $$k$$
  - $$\mu_{c}(i)$$: cluster centroid of cluster to which example $$x^{(i)}$$ has been assigned
  - cost function
    - $$J(c^{(1)},c^{(2)},...,c^{(m)},\mu_{1},...,\mu_{k})=\frac{1}{m}\sum^{m}_{i=1}||x^{(i)}-\mu_{c}(i)||^2$$
    - $$$$\underset{c^{(1)},...,c^{(m)},\mu_{1},...\mu_{k}}{minimize}\ J(c^{(1)},...,c^{(m)},\mu_{1},...,\mu_{k})$$$$
- Initializing K-means
  - Random initialization
    - Run K-means 50-1000 times, compute cost function $$J$$
    - Pick set of clusters that gave lowest cost $$J$$
- Choosing the number of clusters: right value of $$K$$
  - Elbow method: plot cost function $$J$$ as a function of $$K$$ (number of clusters)
    - But the right $$K$$ is often ambiguous
  - Often, you want to get clusters for some later (downstream) purpose
  - Evaluate K-means based on how well it performs on that later purpose
